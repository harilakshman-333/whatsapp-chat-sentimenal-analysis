{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Whatsapp chat analyzer.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPBNV+T6ASvh68FRpKIoAJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harilakshman-333/whatsapp-chat-sentimenal-analysis/blob/main/Whatsapp_chat_analyzer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9MlzPuN0O63",
        "outputId": "4bb5d50c-abc4-4047-fa48-a161317792a9"
      },
      "source": [
        "\n",
        "%pip install emoji\n",
        "import re\n",
        "import regex\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import emoji\n",
        "import plotly.express as px\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "% matplotlib inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.6/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8vwl3p8rneN"
      },
      "source": [
        "def startsWithDateAndTime(s):\n",
        "    # regex pattern for date.(Works only for android. IOS Whatsapp export format is different. Will update the code soon\n",
        "    pattern = '^([0-9]+)(\\/)([0-9]+)(\\/)([0-9][0-9]), ([0-9]+):([0-9][0-9]) -'\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeAlyPZJwVpQ"
      },
      "source": [
        "# Finds username of any given format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wql_oQcOwXs9"
      },
      "source": [
        "def FindAuthor(s):\n",
        "    patterns = [\n",
        "        '([\\w]+):',                        # First Name\n",
        "        '([\\w]+[\\s]+[\\w]+):',              # First Name + Last Name\n",
        "        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # First Name + Middle Name + Last Name\n",
        "        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number (India)\n",
        "        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Mobile Number (US)\n",
        "        '([\\w]+)[\\u263a-\\U0001f999]+:',    # Name and Emoji              \n",
        "    ]\n",
        "    pattern = '^' + '|'.join(patterns)\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I51N7mz1wedt"
      },
      "source": [
        "def getDataPoint(line):   \n",
        "    splitLine = line.split(' - ') \n",
        "    dateTime = splitLine[0]\n",
        "    date, time = dateTime.split(', ') \n",
        "    message = ' '.join(splitLine[1:])\n",
        "    if FindAuthor(message): \n",
        "        splitMessage = message.split(': ') \n",
        "        author = splitMessage[0] \n",
        "        message = ' '.join(splitMessage[1:])\n",
        "    else:\n",
        "        author = None\n",
        "    return date, time, author, message\n",
        "\n",
        "parsedData = [] # List to keep track of data so it can be used by a Pandas dataframe"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLlqBYHWwwmo"
      },
      "source": [
        "# Upload your file here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl7ljrq-wscn"
      },
      "source": [
        "conversationPath = '/content/WhatsApp Chat with F.R.I.E.N.D.S♥️💯.txt' # chat file\n",
        "with open(conversationPath, encoding=\"utf-8\") as fp:\n",
        "    fp.readline() # Skipping first line of the file because contains information related to something about end-to-end encryption\n",
        "    messageBuffer = [] \n",
        "    date, time, author = None, None, None\n",
        "    while True:\n",
        "        line = fp.readline() \n",
        "        if not line: \n",
        "            break\n",
        "        line = line.strip() \n",
        "        if startsWithDateAndTime(line): \n",
        "            if len(messageBuffer) > 0: \n",
        "                parsedData.append([date, time, author, ' '.join(messageBuffer)]) \n",
        "            messageBuffer.clear() \n",
        "            date, time, author, message = getDataPoint(line) \n",
        "            messageBuffer.append(message) \n",
        "        else:\n",
        "            messageBuffer.append(line)\n",
        "   \n",
        "df = pd.DataFrame(parsedData, columns=['Date', 'Time', 'Author', 'Message']) # Initialising a pandas Dataframe.\n",
        "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "DehHBZEX0vLq",
        "outputId": "73b1409b-5666-44cc-d70a-48e56c66e0b0"
      },
      "source": [
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Time</th>\n",
              "      <th>Author</th>\n",
              "      <th>Message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-11-26</td>\n",
              "      <td>20:49</td>\n",
              "      <td>None</td>\n",
              "      <td>Muzammil created group \"F.R.I.E.N.D.S\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>22:12</td>\n",
              "      <td>None</td>\n",
              "      <td>Muzammil added you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>22:12</td>\n",
              "      <td>Anitha Vvd</td>\n",
              "      <td>Ena da nadakudhu enga</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>22:13</td>\n",
              "      <td>Priyanka Vvd</td>\n",
              "      <td>Pesadha ni kelambu peh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>22:13</td>\n",
              "      <td>Muzammil</td>\n",
              "      <td>Inga illa anga thaan 😂😂</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date   Time        Author                                 Message\n",
              "0 2019-11-26  20:49          None  Muzammil created group \"F.R.I.E.N.D.S\"\n",
              "1 2020-02-07  22:12          None                      Muzammil added you\n",
              "2 2020-02-07  22:12    Anitha Vvd                   Ena da nadakudhu enga\n",
              "3 2020-02-07  22:13  Priyanka Vvd                  Pesadha ni kelambu peh\n",
              "4 2020-02-07  22:13      Muzammil                 Inga illa anga thaan 😂😂"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPAiYdBhnh1y",
        "outputId": "dad53878-1aef-4a5e-e4f0-a90d634b8b95"
      },
      "source": [
        "df.info()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12855 entries, 0 to 12854\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   Date     12855 non-null  datetime64[ns]\n",
            " 1   Time     12855 non-null  object        \n",
            " 2   Author   12829 non-null  object        \n",
            " 3   Message  12855 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(3)\n",
            "memory usage: 401.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_dp9FZoofYi"
      },
      "source": [
        "df = df.dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTylM3AqoD6o",
        "outputId": "2ce9cac5-88dc-4b33-b80e-211c0bd3bd47"
      },
      "source": [
        "df.Author.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Anitha Vvd', 'Priyanka Vvd', 'Muzammil', 'Kavya', 'Lakshman⚽',\n",
              "       'Vignesh J'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zISI5v7oomA"
      },
      "source": [
        "def split_count(text):\n",
        "\n",
        "    emoji_list = []\n",
        "    data = re.findall(r'\\X', text)\n",
        "    for word in data:\n",
        "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
        "            emoji_list.append(word)\n",
        "\n",
        "    return emoji_list\n",
        "\n",
        "total_messages = df.shape[0]\n",
        "media_messages = df[df['Message'] == '<Media omitted>'].shape[0]\n",
        "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
        "emojis = sum(df['emoji'].str.len())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CtO9CjvvRJK",
        "outputId": "d8169afb-f909-4cd9-b9df-a363e3c1d8f4"
      },
      "source": [
        "print(\"Group wise Stat\")\n",
        "print (\"Emojis :\", emojis)\n",
        "print (\"Messages :\", total_messages)\n",
        "print (\"Media :\", media_messages)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Group wise Stat\n",
            "Emojis : 0\n",
            "Messages : 12829\n",
            "Media : 1795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "r1TagT4tKWHM",
        "outputId": "be9ca91f-7779-419e-a654-01025cfe6313"
      },
      "source": [
        "# Creates a list of unique Authors - ['Manikanta', 'Teja Kura', .........]\n",
        "l = messages_df.Author.unique()\n",
        "\n",
        "for i in range(len(l)):\n",
        "  # Filtering out messages of particular user\n",
        "  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
        "  # req_df will contain messages of only one particular user\n",
        "  print(f'Stats of {l[i]} -')\n",
        "  # shape will print number of rows which indirectly means the number of messages\n",
        "  print('Messages Sent', req_df.shape[0])\n",
        "  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
        "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
        "  print('Words per message', words_per_message)\n",
        "  #media conists of media messages\n",
        "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
        "  print('Media Messages Sent', media)\n",
        "  # emojis conists of total emojis\n",
        "  emojis = sum(req_df['emoji'].str.len())\n",
        "  print('Emojis Sent', emojis)\n",
        "  #links consist of total links\n",
        "  links = sum(req_df[\"urlcount\"])   \n",
        "  print('Links Sent', links)   \n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-d4a3b32d942f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creates a list of unique Authors - ['Manikanta', 'Teja Kura', .........]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmessages_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Filtering out messages of particular user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'messages_df' is not defined"
          ]
        }
      ]
    }
  ]
}